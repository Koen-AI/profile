<!DOCTYPE HTML>
<!--
	Hyperspace by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Differential evolution in a MARL setting</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Header -->
			<header id="header">
				<a href="index.html" class="title">Hyperspace</a>
				<nav>
					<ul>
						<li><a href="index.html">Home</a></li>
                        <li><a href="generic.html" class="active">Generic</a></li>
						<li><a href="master_thesis.html" class="active">NDE</a></li>
						<li><a href="elements.html">Elements</a></li>
					</ul>
				</nav>
			</header>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<section id="main" class="wrapper">
						<div class="inner">
							<h1 class="major">A Generic Page</h1>
							<span class="image fit"><img src="images/pic04.jpg" alt="" /></span>
							<p> 
                                I wrote my Master's thesis about solving multi-agent reinforcement learning problems using an evolutionary algorithm, namely, differential evolution. 
                                Evolutionary algorithms are optimization algorithms that can find global optima in multi-dimensional vector spaces.
                                Moreover, evolutionary algorithms have successfully solved single-agent reinforcement learning problems before.
                                This leads to our research question: Is differential evolution better suited to deal with the challenges of multi-agent reinforcement learning problems than gradient-based reinforcement learning methods?
                            </p>
                            <p>
                                We speculated that evolutionary algorithms would be better at dealing with the following four issues that temporal difference based methods struggle with:
                                1 Non-stationarity: If one agent changes its policy, the environment changes for all other agents.
                                2 Credit assignment: To what extend did an agents own actions contribute to a group reward or penalty?
                                3 Partial observability: An agent may not have access to all information about the state of an environment.
                                4 Computational complexity: Modeling several agents and updating several policies can increase the computational complexity of MARL problems with respect to RL problems.
                            </p>
							<p>To answer this research question we compared the performance of three different algorithms on two different environment and evaluated their performance after a similar number of playthroughs (fitness evaluations in evolutionary algorithm terms).</p>
						</div>
					</section>

			</div>

		<!-- Footer -->
			<footer id="footer" class="wrapper alt">
				<div class="inner">
					<ul class="menu">
						<li>&copy; Untitled. All rights reserved.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
					</ul>
				</div>
			</footer>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>